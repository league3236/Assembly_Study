{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow Study.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/league3236/Assembly_Study/blob/master/Tensorflow_Study.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8Hqx6WwOG9qo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7yxQD3pjHUnA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "텐서프로우는 기계학습과 딥러닝을 위해 구글에서 만든 오픈소스 라이브러리\n",
        "\n",
        "데이터 플로우 그래프\n",
        "데이터 플로우 그래프는 수학 계산과 데이터의 흐름을 노드와 엣지를 사용한 방향 그래프로 표시합니다.\n",
        "\n",
        "노드는 수학적 계산, 데이터 입/출력, 그리고 데이터의 읽기/저장 등의 작업을 수행합니다. 엣지는 노드들 간 데이터의 입출력 관계를 나타냅니다.\n",
        "\n",
        "엣지는 동적 사이즈의 다차원 데이터 배열(=텐서)을 실어나르는데, 여기에서 텐서플로우라는 이름이 지어졌습니다.\n",
        "\n",
        "텐서(Tensor)는 과학과 공학 등 다양한 분야에서 이전부터 쓰이던 개념입니다. 수학에서는 임의의 기하 구조를 좌표 독립적으로 표현하기 위한 표기법으로 알려져 있지만, 분야마다 조금씩 다른 의미로 사용됩니다. 여기에서는 학습 데이터가 저장되는 다차원 배열 정도로 이해하시면 되겠습니다.\n",
        "\n",
        "특징\n",
        "텐서플로우는 다음과 같은 특징을 가집니다:\n",
        "\n",
        "데이터 플로우 그래프를 통한 풍부한 표현력\n",
        "코드 수정 없이 CPU/GPU 모드로 동작\n",
        "아이디어 테스트에서 서비스 단계까지 이용 가능\n",
        "계산 구조와 목표 함수만 정의하면 자동으로 미분 계산을 처리\n",
        "Python/C++를 지원하며, SWIG를 통해 다양한 언어 지원 가능\n",
        "\n",
        "\n",
        "텐서플로우는 설치가 비교적 쉬운 편입니다만, 다음과 같은 제약이 있습니다:\n",
        "\n",
        "Unix계열 OS(Linux/Mac OSX)만 지원합니다.\n",
        "GPU 버전은 Linux만 지원합니다.\n",
        "\n",
        "\n",
        "\n",
        "참고 : https://gist.github.com/haje01/202ac276bace4b25dd3f"
      ]
    },
    {
      "metadata": {
        "id": "3zMNSOY7HUPi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "ZqobbImUH6NV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "어\n",
        "오퍼레이션(Operation)\n",
        "그래프 상의 노드는 오퍼레이션(줄임말 op)으로 불립니다. 오퍼레이션은 하나 이상의 텐서를 받을 수 있습니다. 오퍼레이션은 계산을 수행하고, 결과를 하나 이상의 텐서로 반환할 수 있습니다.\n",
        "\n",
        "텐서(Tensor)\n",
        "내부적으로 모든 데이터는 텐서를 통해 표현됩니다. 텐서는 일종의 다차원 배열인데, 그래프 내의 오퍼레이션 간에는 텐서만이 전달됩니다. (Caffe의 Blob과 유사합니다.)\n",
        "\n",
        "세션(Session)\n",
        "그래프를 실행하기 위해서는 세션 객체가 필요합니다. 세션은 오퍼레이션의 실행 환경을 캡슐화한 것입니다.\n",
        "\n",
        "변수(Variables)\n",
        "변수는 그래프의 실행시, 패러미터를 저장하고 갱신하는데 사용됩니다. 메모리 상에서 텐서를 저장하는 버퍼 역할을 합니다.\n",
        "\n",
        "예제\n",
        "간단한 예제를 통해 기본 개념을 확인하겠습니다."
      ]
    },
    {
      "metadata": {
        "id": "zcwCoXKXH5HN",
        "colab_type": "code",
        "outputId": "4899a039-425d-410c-d826-a2bb630d9358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#변수를 0으로 초기화\n",
        "state = tf.Variable(0, name=\"counter\")\n",
        "\n",
        "#state에 1을 더할 오퍼레이션 생성\n",
        "one = tf.constant(1)\n",
        "new_value = tf.add(state, one)\n",
        "update = tf.assign(state, new_value)\n",
        "\n",
        "_"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "Xz1PO6KpuB-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83b2fdb1-85df-48b7-a9e5-32f909df1a9d"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Numpy 랜덤으로 100개의 가짜 데이터 채우기. (float64 -> float32로 변환)\n",
        "x_data = np.float32(np.random.rand(2, 100))\n",
        "\n",
        "# 학습 레이블(목표값)은 아래의 식으로 산출. (W = [0.1, 0.2], b = 0.3)\n",
        "y_data = np.dot([0.100, 0.200], x_data) + 0.300\n",
        "\n",
        "# b는 0,\n",
        "b = tf.Variable(tf.zeros([1]))\n",
        "# W는 1x2 형태의 웨이트 변수 (균등 랜덤값으로 초기화)\n",
        "W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))\n",
        "y = tf.matmul(W, x_data) + b\n",
        "\n",
        "# 손실 함수 정의\n",
        "loss = tf.reduce_mean(tf.square(y - y_data))\n",
        "# 경사하강법으로 손실 함수를 최소화 (0.5는 학습 비율)\n",
        "optimizer = tf.train.GradientDescentOptimizer(0.5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"random_uniform_1:0\", shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eMXA14yB1BPU",
        "colab_type": "code",
        "outputId": "09c2ecdb-415d-43fd-af3a-2fb1efa9ae6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#X and Y data \n",
        "x_train = [1, 2, 3]\n",
        "y_train = [1, 2, 3]\n",
        "\n",
        "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hypothesis = x_train*W+b\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "#Fit the line\n",
        "for step in range(5001):\n",
        "  sess.run(train)\n",
        "  if step % 1000 == 0:\n",
        "    print(step, sess.run(cost), sess.run(W), sess.run(b))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1.673539 [-0.01049632] [1.0245973]\n",
            "1000 0.0017645567 [0.95121187] [0.11090678]\n",
            "2000 1.4324801e-05 [0.99560416] [0.00999279]\n",
            "3000 1.1642188e-07 [0.99960357] [0.00090092]\n",
            "4000 9.637992e-10 [0.99996394] [8.188122e-05]\n",
            "5000 1.1847116e-11 [0.9999958] [9.026842e-06]\n",
            "[1.0000049 2.0000007 2.9999967]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BZZkuIII1-Ep",
        "colab_type": "code",
        "outputId": "a8e6389c-700c-4586-c888-f8ff4bf4250e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "X = tf.placeholder(tf.float32)\n",
        "Y = tf.placeholder(tf.float32)\n",
        "\n",
        "\n",
        "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hypothesis = x_train*W+b\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "#Fit the line\n",
        "for step in range(2001):\n",
        "  cost_val, W_val, b_val, _ = sess.run([cost, W, b, train],feed_dict={X: [1, 2, 3],\n",
        "                                                                     Y:[1, 2, 3]})\n",
        "  if step % 100 == 0:\n",
        "    print(step, cost_val, W_val,b_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 20.721062 [-0.6266886] [-0.56961334]\n",
            "100 0.0013323744 [0.9576952] [0.09613556]\n",
            "200 0.00082333246 [0.96675414] [0.07557563]\n",
            "300 0.00050876924 [0.97386575] [0.05940938]\n",
            "400 0.00031438775 [0.9794561] [0.04670119]\n",
            "500 0.00019427172 [0.98385066] [0.03671123]\n",
            "600 0.000120049364 [0.9873051] [0.02885845]\n",
            "700 7.4182615e-05 [0.9900206] [0.02268549]\n",
            "800 4.584083e-05 [0.9921553] [0.01783279]\n",
            "900 2.8326986e-05 [0.99383336] [0.0140182]\n",
            "1000 1.7504202e-05 [0.9951525] [0.01101956]\n",
            "1100 1.0816711e-05 [0.9961894] [0.00866236]\n",
            "1200 6.6839366e-06 [0.9970045] [0.0068094]\n",
            "1300 4.1303124e-06 [0.99764526] [0.00535285]\n",
            "1400 2.552241e-06 [0.9981489] [0.00420788]\n",
            "1500 1.577193e-06 [0.9985449] [0.00330783]\n",
            "1600 9.746537e-07 [0.99885607] [0.00260031]\n",
            "1700 6.02307e-07 [0.99910074] [0.0020442]\n",
            "1800 3.7227483e-07 [0.9992931] [0.00160706]\n",
            "1900 2.3004291e-07 [0.9994442] [0.0012634]\n",
            "2000 1.4225044e-07 [0.99956304] [0.00099337]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZCm3n1O5GZeO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "X = tf.placeholder(tf.float32, shape=[None])\n",
        "Y = tf.placeholder(tf.float32, shape=[None])\n",
        "\n",
        "#Our hypothesis XW+b\n",
        "hypothesis = X*W + b\n",
        "\n",
        "# cost/loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "#Minimize\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "train = optimizer.minimize(cost)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}